---
class: content
---

<div class="doc-header">
  <h1>「半分組み込まない」ロボコン</h1>
  <div class="doc-author">もるもるぷいかー</div>
</div>

# 「半分組み込まない」ロボコン

ソフトウェアの品質を競う ET（Embedded Technology, 組み込み技術）ソフトウェアデザインロボットコンテスト (**ETロボコン**) では、ハードウェアの開発をほとんど行いません。本稿では、「半分組み込まない」ロボコンである ET ロボコンについて、私が所属するチーム KatLab での開発体験を交えてご紹介いたします。

## ET ロボコンとは

ロボットコンテスト（ロボコン）はチーム、もしくは個人がロボットを作成し、それを用いて技術的な課題をクリアすることを競う競技です。
著名なロボコンに、アイデア対決・全国高等専門学校ロボットコンテスト[^高専ロボコン]（高専ロボコン）や、NHK 学生ロボットコンテスト[^NHK学生ロボコン]などがあります。これらのロボコンに限らず、一般的なロボコンのイメージから、「ロボコン = ハードウェア開発 + ソフトウェア開発」と認識している方が多いでしょう。

[^高専ロボコン]: 高専ロボコン, 高専ロボコン, <http://official-robocon.com/kosen/>, 最終アクセス日：2025/05/03

[^NHK学生ロボコン]: 高専ロボコン, NHK 学生ロボコン<http://official-robocon.com/kosen/>, 最終アクセス日：2025/05/03

その中でも ET ロボコンは、世界的にもユニークな**ソフトウェア重視**の教育ロボコン[^ETロボコン公式サイト]です。
ET ロボコンは、組込みシステム技術協会が主催するロボコンであり、高校生以上であることを参加条件としています。
プログラミング未経験の学生から、組み込み系で有名な企業所属の社会人まで幅広く参加しています。

[^ETロボコン公式サイト]: ET ロボコン, 組込みソフトウェア技術教育をテーマとした「ET ロボコン」, <https://www.etrobo.jp/>, 最終アクセス日：2025/05/03

ET ロボコンには、ロボットに実際にコース上を走らせて得点を競う**競技部門**と、開発したソフトウェアを記述対象とした設計書の出来を競う**モデル審査部門**があります。
総合成績は 2 つの成績を正規化して決定するため、好成績を収めるには片方の成績だけが突出しているだけでは不十分です。
設計書の提出が義務付けられている点からも、ソフトウェア開発力が重視される、珍しいロボコンだといえます。

出場クラスはレベルに応じて、プログラミングや設計について入門者向けのエントリークラス、中級者向けのプライマリークラス、上級者向けのアドバンストクラスがあります。参加者は自らのレベルを考慮し、参加するクラスを決定します。
私が参加する宮崎大学の学生チーム KatLab は、アドバンストクラスに参加しました。
2024 年度は、全クラス合計で 195 チームが参加しており、アドバンストクラスは計 18 チームが参加しました。

以降、KatLab が参加しているアドバンストクラスでの内容について記述いたします。

## ETロボコンの特徴

本章では、ET ロボコンの大きな 3 つの特徴について紹介いたします。
以降、ET ロボコンにおいて用いるロボットを**走行体**、運営に提出する設計書を**モデル**と呼びます。

- 全チームで走行体が共通
- ソフトウェア開発が中心
- 総合成績が「走行」と「設計」で決定

### 全チームで走行体が共通

チームごとに特色あるロボットが動く様子を見られるのは、ロボコンの醍醐味のひとつでしょう。
しかし ET ロボコンは、どのチームも共通の走行体を用いて競技に参加します。
ET ロボコン走行キット[^ETロボコン走行キット] という、レゴ® エデュケーション SPIKE™ プライムセット[^SPIKE]（以降 SPIKE）や、Raspberry Pi[^Raspberry_Pi] などを組み合わせたキットが市販されています。
全チームがそのキットを組み立て、作成した走行体を走らせます。

[^ETロボコン走行キット]: Afrel, ET ロボコン走行キット<https://afrel.co.jp/product/et-set/>, 最終アクセス日：2025/05/01

[^SPIKE]: LEGO® Education, レゴ® エデュケーション SPIKE™ プライムセット, <https://education.lego.com/ja-jp/products/lego-education-spike-prime-set/45678/>, 最終アクセス日：2025/05/01

[^Raspberry_Pi]: アイ・オー・データ機器｜I-O DATA, Raspberry Pi 4 Model B（UD-RP4B シリーズ）仕様, <https://www.iodata.jp/product/pc/raspberrypi/ud-rp4b/spec.htm>, 最終アクセス日：2025/05/01

### ソフトウェア開発が中心

前述したとおり、全チームで共通の走行体を走らせます。
走行体はキットの組み立てで完成し、回路やアクチュエーターなどのハードウェア寄りの開発がほとんどありません。

走行体は、SPIKE-RT[^SPIKE-RT] という RTOS（Real-Time Operating System）を SPIKE に搭載しています。
プログラミング言語 C++ によって SPIKE API [^SPIKE-API] を通じてモーターの駆動や、センサーでの測定値取得などを行います。
実際の開発環境では、ET ロボコン運営が用意する RasPike-ART[^RasPike-ART] という Raspberry Pi と SPIKE の制御開発環境を通じて SPIKE API を呼び出し、走行体を制御します。

ET ロボコンにおける各チームの開発対象は、走行体を制御するソフトウェアがほとんどです。
よって、一般的なロボコンを「ロボコン = ハードウェア開発 + ソフトウェア開発」とするならば、ET ロボコンは「半分組み込まない」ロボコンと形容できるでしょう。

[^SPIKE-RT]: GitHub, spike-rt, <https://github.com/spike-rt/spike-rt>, 最終アクセス日：2025/05/03

[^SPIKE-API]: SPIKE-RT C API Reference[Japanese], <https://spike-rt.github.io/spike-rt/ja/html/modules.html>, 最終アクセス日：2025/05/03

[^RasPike-ART]: GitHub, RasPike-ART, <https://github.com/ETrobocon/RasPike-ART>, 最終アクセス日：2025/05/03

### 総合成績が「走行」と「設計」で決定

ET ロボコン最大の特徴のひとつは、設計が成績の半分を占めることです。
大規模化・複雑化するソフトウェア開発において、ソースコードのみを追跡して開発を進めることは困難です。
そこで、設計をある視点で抽象化 (**モデリング**) することで、大規模化するソフトウェアの全体像が把握しやすくなります。

ソフトウェア開発を重視した教育ロボコンである ET ロボコンでは、モデリングした設計書であるモデルを成果物として提出することを、全クラスで義務付けています。
いわゆる **UML**（Unified Modeling Language）や **SysML**（Systems Modeling Language）といったモデリング言語を用います。

ET ロボコンは、1 年に地区大会とチャンピオンシップ大会（全国大会）の 2 回が開催され、地区大会を勝ち抜けばチャンピオンシップ大会に出場できます。
競技部門とモデル審査部門がそれぞれ評価され、総合成績が確定します。

## 大会の詳細とチーム KatLab の攻略方法

本章では、大会の詳細として 2024 年度開催の ET ロボコン 2024 の内容のうち、競技部門に関することを 3 つと、モデルについて紹介いたします。
同時に、チーム KatLab が ET ロボコン攻略のために立てた戦略を紹介いたします。

モデルについては、言語化すると長文となってしまったため、かなりわかりにくくなっています。
しかし、読みにくいことを承知で書いています。
構造や処理のフローをモデルという形で抽象化することで、プログラム全体の理解が容易となることを、ぜひ実感していただきたいと考えているためです。

記述する図などは、ET ロボコン実行委員会が配布している次の資料から引用いたします。

- ET ロボコン 2024 競技規約 1.0.2 版[^公式規約]
- ET ロボコン 2024 難所組立図 1.0.0 版[^難所攻略図]
- ET ロボコン 2024 審査規約 1.0 版[^審査規約]

なお、モデル内では EV3API という記述があります。
これは SPIKE API と同じような機構がある別物ですが、本稿内では区別する必要がないため、SPIKE API と統一して記述いたします。

以降、KatLab が提出したモデルの画像を示しています。
紙面では見にくいという方向けに、モデルの画像を Google Drive に共有フォルダとしてまとめました。
拡大してモデルの画像を見たい方は、次のリンク、もしくは QR コードからご覧ください。
モデルの画像をまとめた Google Drive の QR コードを、図 1 に示します。

```url
https://drive.google.com/drive/folders/1r0xD7jiTnK6KrH1i7InL1uyFjWCyJ-F2?usp=drive_link
```

![モデルの画像を集めた Google Drive の QR コード](./images_yu_kimura/google_drive_qr_code.png 'モデルの画像を集めた Google Drive の QR コード')

[^公式規約]: ET ロボコン実行委員会, ET ロボコン 2024 競技規約 1.0.2 版, <https://docs.etrobo.jp/rules/2024/ETRC2024_rules_primary_advanced_1.0.2.pdf>, 最終アクセス日：2025/05/01

[^難所攻略図]: ET ロボコン実行委員会, ET ロボコン 2024 難所組立図 1.0.0 版, <https://docs.etrobo.jp/rules/2024/ETRC2024_nansyo_1.0.0.pdf>, 最終アクセス日：2025/05/01

[^審査規約]: ET ロボコン実行委員会, ET ロボコン 2024 審査規約 1.0 版, <https://docs.etrobo.jp/rules/2024/ETRC2024_dev_shinsa_rules_V1.0.pdf>, 最終アクセス日：2025/05/01

### 競技部門

ET ロボコン 2024 で走行体が走るコースの全景を、図 2 に示します。
コースは図 2 左半分の L コースと右半分の R コースからなります。
各コースは、もう一方のコースを左右反転させたものであり、競技内容や獲得するポイントは変わりません。
簡単のため、本稿では L コースを例として説明いたします。
各コースにつき 1 回、計 2 回の走行で獲得したポイントを比較し、高いポイントのほうを競技部門の成績として採用します。

![コースの全景](./images_yu_kimura/course.png 'コースの全景')

競技部門のポイントは、ポイント獲得対象として、走行ポイントとボーナスポイントの 2 種類のポイントがあり、それらの合計で算出されます。

走行ポイントは、スタート（図 2 中の①）からラップゲート（図 2 中の②）を通過するまでの走行時間に応じて与えられます。
ラップゲート通過までの時間を短縮するほど、獲得できる走行ポイントは高くなります。

ボーナスポイントは、ラップゲート通過や難所攻略など、ある特定の条件を達成した際に獲得できるポイントです。
難所の攻略状況によって、獲得できるポイントは上下する場合があります。

なお、ポイントを算出する式や難所あたりで獲得できる具体的なポイント数などについては、省略いたします。

#### 走行体の制御

KatLab は、走行体にコース上を走らせるため、ライントレースを採用しました。
プログラミング言語は、走行体の制御はリアルタイムな動作制御が必要であるため、C++ 言語を採用しました。
L コースについては、黒線の左境界を中心（左エッジ）として、走行体下部にあるカラーセンサーが白色を検知すると右前方へ、黒色を検知すると左前方へ進むよう実装しました。
走行体の正面下部にあるカラーセンサーは LED ライトを備えており、コースに向かって光を放ちます。
その反射光をカラーセンサーが読み取ることで、反射光の RGB 値を取得し、色を判定します。
これにより、走行体は黒線の左境界を中心にジグザグと前方に進みます。
L コースを走行体がライントレースした際のイメージ図を、図 3 に示します。

![ライントレースのイメージ図（L コース）](./images_yu_kimura/line_trace.png 'ライントレースのイメージ図（L コース）')

制御方法として、 PID 制御を採用しています。
同時に、走行区間に応じて PID の各ゲインを調節できるようにしています。
これにより、直線区間とカーブ区間での曲がりやすさをそれぞれ決められます。
特にカーブ区間では、白色を検知した際の曲がりやすさを高めることで、単に速度を落とす場合と比べて、コースアウトのリスクをより効果的に低減できます。

#### プラレール・背景撮影

2 つの円のうち真円のエリア（図 2 中の③）では、真円中心の四角柱の側面ひとつにある背景と、その周囲を周回する 3 両のプラレールを収めて画像を撮影することで、ボーナスポイントを獲得できます。
背景のみ、プラレールのみの撮影でも一定のポイントは獲得できます。
しかし、背景とプラレール 3 両側面を同じ画像に収めて撮影することで、獲得できるポイントが高くなります。
プラレール・背景撮影を攻略している走行体の様子を、図 4 に示します。

![プラレール・背景撮影攻略中の走行体](./images_yu_kimura/snap_plarail.png 'プラレール・背景撮影攻略中の走行体')

KatLab は、動画の録画と動体検知によって上限の点数を獲得できました。
プログラミング言語は、Raspberry Pi のカメラモジュールについて豊富なライブラリが存在するため、 Python を採用しました。
背景がある面の方向は、当日の本番前に決定します。真円を 60 度ずつ分割し、6 箇所の撮影箇所を定義しました。
6 つの撮影箇所のうち、背景を撮影できる箇所を指定するパラメータを持たせました。
走行前にパラメータを設定する方法を採用し、背景を撮影できました。
さらに、プラレール 3 両側面を撮影するため、プラレールがカメラの前を通過する区間における中間のフレームを特定し、中間フレームの画像を切り出す方法を採用しました。

具体的には、次のように実装しました。

1. 背景をカメラ正面で捉えるため真円内側へ回転する
2. カメラ中央にバウンディングボックスを配置する
3. 録画を開始する
4. プラレールがバウンディングボックスに侵入したタイミングを計測する
5. プラレールがバウンディングボックスを退出したタイミングを計測する
6. 録画を停止する
7. 録画した動画から、計測したバウンディングボックス侵入・退出タイミングから中間のフレームを切り出す

難所組立図には、本番に用いるプラレールの画像がありませんでした。
機械学習による実装では、プラレールの種類によっては学習モデルが合わず、本番でプラレールをうまく検出できない場合があると考えました。
そこで、画像処理の中でも、プラレールの種類によらない方法である動体検知で実装しました。
バウンディングボックスにプラレールが侵入したときのフレームと、退出したときのフレーム、中間のフレームを、図 5 に示します。

![中間フレームの切り出し](./images_yu_kimura/snap_plarail_image.png '中間フレームの切り出し')

#### ミニフィグ撮影

2 つの円のうち楕円のエリア（図 2 中の④）では、楕円中心にあるミニフィグの画像を撮影することで、ボーナスポイントを獲得できます。
ミニフィグ全身と台座が映っていれば、どの方向から撮影しても一定のポイントを獲得できます。
しかし、ミニフィグ正面（両目、口が判別できる状態）から撮影することで、獲得できるポイントが高くなります。
ミニフィグ撮影を攻略している走行体の様子を、図 6 に示します。

![ミニフィグ撮影攻略中の走行体](./images_yu_kimura/snap_fig.png 'ミニフィグ撮影攻略中の走行体')

KatLab は、機械学習と画像処理によって上限の点数を獲得できました。
プログラミング言語は、プラレール・背景撮影と同様の理由から、Python を採用しました。
プラレール撮影の背景とは異なり、ミニフィグの向きは走行直前に決まります。このタイミングは PC と走行体には触れられないため、パラメータとして設定できません。
また、本番で使用するミニフィグの種類は、難所組立図に記載されていました。
そこで、機械学習によってミニフィグの向きを判定する方法を採用しました。

具体的には、次のように実装しました。

1. ミニフィグの向きを判定するため、事前に決定した箇所からミニフィグを撮影する
2. 無線接続している PC へ走行体から撮影した画像を送信する
3. 1. で撮影した画像から、ミニフィグの向き（正面、右面、左面、背面）を機械学習で判定する
4. 判定した方向が正面である場合、1. で撮影した画像を提出する
5. 判定した方向が正面でない場合、判定した方向に応じた撮影箇所へ移動し、ミニフィグを撮影する

YOLO v5 を用いて、画像からミニフィグを物体検知し、正面、右面、背面、左面の 4 つからミニフィグの向きを判定します。
当初は走行体の Raspberry Pi で推論する予定でしたが、使用している Raspberry Pi OS が 32 bit でした。
YOLO の環境構築時、Raspberry Pi OS が 64 bit でないと推論できないことがわかりました。
そこで、走行体へ無線通信している PC へ画像を送信し、PC で推論する方針に切り替えました。

また、4. の条件に入り、ミニフィグの向きを判定するために撮影した 1. の画像を提出した場合は、5. の移動と撮影はスキップする処理を実装しています。
この処理によって、4. の条件に入った場合は 2 回目の移動と撮影にかかる時間だけ、難所の攻略にかかる時間を短縮できます。

なんらかの理由でミニフィグの向きを判定できなかった場合は、ミニフィグが正面、右面、背面、左面のどの方向を向いていてもよいよう 4 つの箇所から画像を撮影します。
その後、機械学習で顔の正面らしさのスコアをそれぞれ算出し、もっとも正面らしいスコアが高い画像 1 枚を提出するようにしました。
ミニフィグの向き判定成功時の画像を、図 7 に示します。

![ミニフィグの向き判定（左から正面、右面、背面、左面）](./images_yu_kimura/predict_fig_direction.png 'ミニフィグの向き判定（左から正面、右面、背面、左面）')

### モデル審査部門

モデルは競技部門と異なり、詳細な点数が開示されません。
評価は A から D までの 4 段階に分かれており、それぞれに+と-の記号が付くことで、合計 12 段階の細かい評価が行われます。

モデルは計 6 枚であり、次の 4 つで構成します。
次に示す全体の構成は、アドバンストクラスに参加するチームで共通です。
1 枚目は、モデルの概要を示すページであるため、説明を省略いたします。

1. 要求モデル（2 枚目）
2. 分析モデル（3 枚目）
3. 設計モデル（4, 5 枚目）
4. 制御モデル（6 枚目）

#### 要求モデル

要求モデルでは、開発の目標と、それを達成するために必要な機能、機能に付随する品質や制約の検討がされているかが見られます。

KatLab が書いた要求モデルを、図 8 に示します。
KatLab は、**開発目標**と目標得点を決め、開発目標の達成のための**ユースケース**を定義し、それをもとに導出した**要求**と**要素技術**を要求図に起こしました。

![KatLab の要求モデル](./images_yu_kimura/model/1_requirements_2.png 'KatLab の要求モデル')

ミニフィグ撮影を例に挙げます。
目標とするポイントから逆算して、ミニフィグ撮影では、ミニフィグを正面から撮影した画像を提出することを目標としました。
この目標を達成するためには、カメラで画像を撮影する機能や、ミニフィグを正面から撮影した画像を提出する機能などが必要。
さらに、ミニフィグを正面から撮影した画像を提出する機能を実装するためには、ミニフィグが正面を向いているかを判定する機能と、画像を提出する機能が必要。
このように、上位の要求を満たすために必要なことを、下位の要求として分解します。

このとき、目標達成のために必要な**品質特性**の項目を抽出する必要があります。
これは、通信失敗や撮影失敗時の動作、安定した走行など、保守性や効率性といった非機能要求を指します。
ミニフィグの向き判定が失敗した際は、4 枚の画像から正面らしさのスコアを算出して比較し、もっともスコアの高い画像 1 枚を提出するという要求は、非機能要求にあたります。
この要求がない場合は、撮影失敗やミニフィグの向き判定の失敗を考慮しないことを示します。
この場合、品質特性における信頼性（正しく機能できる度合、異常発生時の回復のしやすさ）が足りていないため、減点されます。

また、上位要求を満たすための下位要求が足りない場合も、減点されます。
たとえば、ミニフィグ正面から画像を撮影するという上位要求を、画像を撮影する、ミニフィグの向きを判定するという 2 つの下位要求に分解するとします。
しかし、この 2 つだけでは上位要求を満たしているといえません。
ミニフィグを正面から撮影できる箇所へ移動するという要求が足りていません。
また、走行体の設計上、カメラモジュールは走行体の正面にあるものを画角に収めるよう設置します。
ただ前方へ進むだけでは、楕円内側にあるミニフィグをカメラの画角に収められない場合がほとんどです。
そのため、ミニフィグがある楕円内側へ向かって回転するという要求が足りていません。
さらに、ミニフィグを正面から撮影できる箇所へ移動するという要求を上位要求として、ミニフィグの向きを判定する、撮影場所へ移動するという下位要求も足りていません。

このように、ルールや走行体の設計、コース設計などを制約として、要求を段階的に追跡できる粒度で分解する必要があります。

#### 分析モデル

分析モデルでは、導出した要求や制約に基づくシステム全体の構造や動作の分析ができているかが見られます。

KatLab が書いた分析モデルを、図 9 に示します。
KatLab は、競技規約からシステム分析による**静的構造**を導出しました。
これにより、ET ロボコン全体、走行体内部のそれぞれの間での関係性を示すことで、**開発対象**と**ソフトウェア開発対象**を、コンテキスト分析でそれぞれ示しました。
また、導出した要求と開発対象から、要素技術を構成する**サブシステム**を定義しました。
サブシステム間でのデータのやりとりである **I/F（インターフェース）**を定義することで、その静的構造を示しました。
さらに、ユースケースを実現できることを示すため、アクティビティ図でサブシステム間の**動的振舞い**を示しました。

![KatLab の分析モデル](./images_yu_kimura/model/2_analysis.png 'KatLab の分析モデル')

プラレール・背景撮影を例に挙げます。
要求モデルにおいて、背景の正面へ移動するという要求の分解を続けた結果、ライントレースの要素技術を導出しました。
まず、競技規約から、分析モデル内で走行体と PC の 2 つを開発対象と定めました。
その中でも、走行体に接続している Raspberry Pi と PC の 2 つをソフトウェア開発対象と定めました。
プラレール・背景撮影に関連する要素技術から、走行全体に関わる走行システムや、カメラ関連の処理を行うフロントカメラシステムなどのサブシステムが必要であるとわかりました。
他の要素技術をサブシステムに配置した結果、計 5 つのサブシステムを定義しました。

次に、サブシステム間でのデータのやりとりである I/F を明確にして、サブシステム間の静的構造を示します。
走行システムは、外部から RGB 値や輝度値を受け取り、SPIKE API へモーター回転指示を渡すなどの I/F を定義します。
ここで、SPIKE API はサブシステムとして定義しておらず、ソフトウェア開発対象ではないことを明記しています。
同様にフロントカメラシステムでは、外部から映像や画像を受け取り、プラレールと背景を撮影した提出用の画像を Raspberry Pi 内の別のサブシステムへ渡すなどの I/F を定義します。

これにより、一部ですが、プラレール・背景撮影に関するサブシステムの静的構造が示せました。
最後に、サブシステム間の I/F を考慮して、動的振舞いを示しました。
走行システムにおいて、プラレールと背景を画角に収めるため、楕円内側に回転するという処理がある。
次の処理で、フロントカメラシステムにおいて、プラレールと背景の画像を撮影するという処理に移る。
このようにサブシステム間の処理の流れを、アクティビティ図に起こすことで、動的振舞いを示しました。

#### 設計モデル

設計モデルでは、システム全体の分析を元に要求を実現する各システムの構造と振舞いの設計が見られます。

KatLab が書いた設計モデルを図 10、図 11 に、それぞれ示します。
要求モデルと分析モデルから注意事項を抽出し、**設計方針**を決定しました。
設計方針に基づいて、サブシステム内の主なソフトウェアの構成要素と I/F を、**アーキテクチャ**としてパッケージ図に示しました。
その後、各サブシステムと各パッケージ間の内部構造と関連性を、**ソフトウェア構造**としてクラス図に示しました（図 10）。

![KatLab の設計モデル（ 1 枚目）](./images_yu_kimura/model/3_design1.png 'KatLab の設計モデル（ 1 枚目）')

ソフトウェア構造から、各難所攻略の流れを表すステートマシン図を示しました。
ステートマシン図内のそれぞれの状態に着目し、主要なユースケースが実現可能であることを、コミュニケーション図に示しました。
さらに、コミュニケーション図に起こしたクラスのうちの 1 つに注目し、他クラスとの**振舞い**をアクティビティ図に示しました（図 11）。

![KatLab の設計モデル（ 2 枚目）](./images_yu_kimura/model/3_design2.png 'KatLab の設計モデル（ 2 枚目）')

プラレール・背景撮影を例に挙げます。
まず、設計 1 枚目の設計方針について説明します。
開発効率について、拡張性を向上するという上位要求を導出しました。
さらにその上位要求から、パッケージ間を疎結合にするという下位要求を導出し、Facade（ファサード）パターンの設計方針を要求モデルで導出しました。
設計方針については、根拠である要求や分析、検討事項の 2 つともに表にまとめて示しました。

次に、同じく設計 1 枚目のアーキテクチャについて説明します。
導出した設計方針である Facade パターンを実現するため、今年の競技固有の機能を束ねたパッケージと、汎用的な機能を束ねたパッケージに分解しました。
たとえば、カメラを用いて画像や動画を撮影する処理は、汎用的な処理にあたります。
対して、プラレールのバウンディングボックス侵入・退出タイミングの判定や、中間フレーム切り出しなどの処理は、今年の競技固有の処理にあたります。
設計方針において、カメラに関するサブシステムであるフロントカメラシステムを、次の 4 つのパッケージに分解しました。

- カメラインターフェース
- 動体検出部
- 画像解析部
- カメラ制御部

動体検出部と画像解析部は、バウンディングボックスの侵入・退出タイミングの判定や、プラレールの中間フレーム切り出しなどの、競技固有の処理をそれぞれ含むパッケージです。
カメラ制御部は、画像や動画の撮影という、汎用的な処理を含むパッケージです。
カメラインターフェースは、動体検出部や画像解析部へ、動体検知指示と画像解析指示をそれぞれ送るインターフェースとなるパッケージです。
このように、パッケージ間の I/F をパッケージ図で示すことで、アーキテクチャを定義しました。
また、フロントカメラシステムにおける保守性と拡張性の向上という非機能要求を、アーキテクチャによって実現していることが示せました。

さらに、同じく設計 1 枚目のソフトウェア構造について説明します。
カメラインターフェースのパッケージ内で、フロントカメラインターフェースという 1 つのクラスを定義しました。
同様に、動体検出部のパッケージ内で、動体検出クラスとプラレール映像解析クラスという 2 つのクラスを定義しました。
動体検出部、画像解析部は、カメラ制御部内の各クラスの public な関数を参照します。
動体検出部と画像解析部の各パッケージにおける処理は、カメラインターフェースで定義した public な関数を経由して参照されます。
このように、パッケージをクラスとして分割し、それらをクラス図に示すことで、ソフトウェア構造を定義しました。

設計 2 枚目に移り、ソフトウェアの振舞いについて説明します。
まず、各難所を攻略する状態をそれぞれ定義し、プラレール・背景撮影を攻略するという状態が、どのような条件で到達するのかを考えます。
2 つの円の難所を攻略するという状態から、真円のエリア到達時に、プラレール・背景撮影攻略中という状態へ遷移することを、ステートマシン図を示しました。
その後、プラレール・背景撮影攻略中の状態におけるクラス内での振舞いを、コミュニケーション図に示しました。
フロントカメラインターフェースクラスは、別のパッケージのとあるクラスから参照されることが、設計 1 枚目に示したクラス図からわかっています。
プラレール・背景撮影中の状態において、フロントカメラインターフェースクラスに着目し、他クラス間との処理の流れを振舞いとしてシーケンス図に示しました。

#### 制御モデル

制御モデルは、要求で定義した品質を満たすための制御戦略と、その戦略で用いられる要素技術についての検討内容と分析結果が見られます。

KatLab が書いた制御モデルを、図 12 に示します。
KatLab は、走行全体、プラレール・背景撮影、ミニフィグ撮影について**制御戦略**が要求を満たすことを確認しました。
走行体の動作を細分化し、図を含めて制御戦略の説明を示しました。
詳細なデータを示せる場合は具体的に、成功率 ◯◯ ％ 達成などと数値を用いて、採用した制御戦略が根拠をもって実現可能であることを定量的に評価しました。

![KatLab の制御モデル](./images_yu_kimura/model/4_control.png 'KatLab の制御モデル')

プラレール・背景撮影を例に挙げます。
競技規約から、真円の内側に背景があることと、背景の向きは、本番当日の走行前に決定することがわかっていました。
真円という形状から、円周上に等間隔で 6 つの撮影箇所を設けることで、6 つの撮影箇所のうちどこか 1 箇所で背景を撮影できると考えました。
しかし、ミニフィグの向きと同様に、プラレールの周回方向は、走行直前に決定します。
このタイミングは PC と走行体には触れられないため、パラメータとして設定できません。
そのため、プラレールの周回方向に依存しない方法でプラレール撮影の機能を実装する必要があるとしました。
ここで、プラレールがバウンディングボックスに侵入したタイミングと、退出したタイミングの中間フレームを切り出す実装について説明しています。

また、競技規約より、背景下部には黄色の矩形があるとわかっていました。
そこで、黄色の矩形がカメラの画角正面に収まるよう、回転の角度を補正する処理を実装しました。
具体的には、大きく回転しすぎた場合は逆回りに、回転角度が足りない場合はさらに同じ方向へ回転します。
これにより、背景をよりカメラ正面で捉えられるようになったため、この難所における上限のポイントを獲得できる確率が 90 ％以上になったと定量的に示しました。

制御モデルは、チームによってかなり差があります。
KatLab は代々、ユニークなツールを作成したことを書いています。
今年は、走行ログ可視化ツールを Web アプリとして作成したことで、走行動作が失敗する原因の特定に寄与したと、走行全体の制御戦略のひとつとして書きました。
昨年は、パラメータ指定ツールを iOS アプリとして作成したことで、PID ゲインなどのパラメータ調整にかかる時間を削減できたと書きました。

## KatLab での体験

本章では、ET ロボコンにおいて、チームを組んだことで得た体験について書きます。

### 大会成績

2024 年度は、九州地区大会で競技部門 2 位、モデル審査部門 1 位、総合 2 位を獲得。
続くチャンピオンシップ大会（全国大会）では、走行・設計・総合すべての部門で 5 位となりました。
KatLab は 2018 年から 7 年連続で全国出場を果たしていたため、その記録を継続させることができました。
企業も参加した中で、学生団体では、総合の成績は上から 2 番目でした。
それを考慮すると、入賞こそ逃しましたが良い成績を収められたと考えています。

### チームリーダーの経験

2024 年度は、私がチームリーダーを務めました。
開発方式については、昨年と同じくアジャイル開発で進めました。
モデルを書くのであればウォーターフォール開発が向いていそうとよくいわれますが、これはイテレーションごとに動作するものを作り上げられるためです。
ウォーターフォール開発は、未完成の段階では各機能の動作が保証できません。
一方でアジャイル開発は、イテレーションごとに動く機能を細かく作成します。
ET ロボコンのコースは、難所の攻略順がおおよそ決まっています。
そのため、途中で動作が止まる、コースアウトするなどで復帰不能となった場合は、以降の得点がすべて失われます。
極端な話、ラップゲート通過前に復帰不能となった場合は、ボーナスポイントはもちろん走行ポイントも入りません。
まずは基礎的な動作を完成させ、次はこの難所攻略、次はこの難所攻略、と段階を踏んで開発を進めることで、開発が間に合わなかった場合に大きく失点するリスクを防いでいます。

マネジメント関連は、常に自分からコミュニケーションを取りにいくことを意識しました。
タスクで困っていることがないか、実装方法がミーティング時から変わったことがないかを積極的に確認していました。
ただ、すべてを把握しようとすると窮屈に思われると考えたため、タスクにつき 1 回や 2 回と意識的に抑えていました。
メンバーが全員優秀だったこともあり、明らかに困っている様子でない限り、タスクごとに分けたグループ内で解決してもらう方針を取りました。
そのため、学生プログラミング団体でありがちな、一部のコーディングを得意とする学生が、開発のほとんどを進行するという状況にはなりませんでした。
これは、平等に学習の機会があったという意味で、よい効果があったと考えています。

### 感想と 2025 年度の目標

学生のうちから設計に関われることは、かなり珍しいと思っています。
それだけに、今しか集まれないメンバーと足並みを揃えて、今しかできない ET ロボコンで得た経験は、自分を形成する上で欠かせない要素だと強く考えています。
こうしてゆめみに内定をもらったり、ゆめみ大技林に寄稿したりすることもなかったでしょう。
優秀なメンバーに囲まれ、リーダーとして特別にやったことは、さほどなかったと記憶しています。
いくつも失敗しましたが、それでもメンバーのみんながフォローしてくれ、最後まで開発できたので大変満足しています。
メンバーのみんなには本当に頭が上がりません。

今年度も、全国大会にて総合 3 位以内で入賞の目標を継続します。
KatLab は 2018 年から 7 年連続で全国出場を果たしているものの、全国での成績が停滞気味です。
今年度こそ、新生 KatLab メンバーで全国入賞を果たします。

## まとめ

まず、ゆめみ大技林の執筆に勧誘いただいた、うーたん様にお礼申し上げます。
ゆめみ大技林の執筆者の方々にも、レビューと推敲をしていただきました。ありがとうございます。
KatLab のチームメンバーの皆さんも、推敲を手伝ってくださりありがとうございました。
昨年活動分の感謝と一緒に、今年の ET ロボコンの活動で返します。

最後に、ここまで閲覧いただきありがとうございます。
アプリというより組み込み、プログラムというより設計と、他の執筆者の方々とは少し外れてしまったテーマでした。
しかし、希少性のあるテーマで寄稿できたという意味で、よいことだと前向きに捉えています。
また、先述したように、モデルの話はかなり長文で理解しにくい内容だったと自覚しています。
だからこそ、システム設計書でソフトウェアの構造や振舞いを理解することや、設計そのものの良し悪しを判断することの重要性を感じていただけたのではないでしょうか。
